# Sensitivity Analysis

## Final hidden state wrt earlier hidden states

How much change is there in the final hidden layer when you perturb an earlier hidden layer?

### Perturbed hidden state

Perturbation hidden states by multiplying by  `1 + (rand(0,1)-0.5)*0.01`

#### Table 1

|perturb hidden states before layer|MSE loss at the end|MSE loss at the end|MSE loss at the end|
|-|-|-|-|
|states perturbed|img|txt|x|
|  0 |  33.0890 +/-   3.7874|  33.7907 +/-   3.8527||
|  1 |  29.1840 +/-   3.1784|  34.3451 +/-   3.9801||
|  2 |  26.1842 +/-   3.0063|  35.6959 +/-   4.1411||
|  3 |  24.9846 +/-   2.9218|  35.9065 +/-   4.1854||
|  4 |  24.6515 +/-   2.7708|  36.6737 +/-   4.3747||
|  5 |  22.8256 +/-   2.6573|  37.1647 +/-   4.3950||
|  6 |  22.3125 +/-   2.5129|  34.4390 +/-   4.1094||
|  7 |  22.7619 +/-   2.6340|  35.4598 +/-   4.1795||
|  8 |  20.7475 +/-   2.4565|  35.4144 +/-   4.3268||
|  9 |  18.6719 +/-   2.1442|  35.5865 +/-   4.3530||
| 10 |  17.0324 +/-   1.9751|  34.2712 +/-   4.1779||
| 11 |  14.6859 +/-   1.7392|  36.1818 +/-   4.5871||
| 12 |  13.2970 +/-   1.5462|  35.3586 +/-   4.3910||
| 13 |  12.7398 +/-   1.5240|  38.8503 +/-   4.8714||
| 14 |  10.5542 +/-   1.1927|  38.4359 +/-   4.7852||
| 15 |   9.4681 +/-   1.1040|  30.6114 +/-   3.7972||
| 16 |   7.9387 +/-   0.9049|  29.5301 +/-   3.7334||
| 17 |   7.1108 +/-   0.8546|  28.0189 +/-   3.5853||
| 18 |   4.8908 +/-   0.5265|  26.4334 +/-   3.4645||
| 19 |||  13.6130 +/-   1.7506|
| 20 |||   9.8836 +/-   1.2649|
| 21 |||   7.7612 +/-   0.9777|
| 22 |||   5.9002 +/-   0.6620|
| 23 |||   4.1810 +/-   0.4079|
| 24 |||   3.0503 +/-   0.2319|
| 25 |||   2.3322 +/-   0.1323|
| 26 |||   2.0017 +/-   0.0830|
| 27 |||   1.9152 +/-   0.0743|
| 28 |||   1.7724 +/-   0.0608|
| 29 |||   1.7068 +/-   0.0549|
| 30 |||   1.6883 +/-   0.0548|
| 31 |||   1.6582 +/-   0.0519|
| 32 |||   1.5941 +/-   0.0522|
| 33 |||   1.5903 +/-   0.0499|
| 34 |||   1.5733 +/-   0.0495|
| 35 |||   1.6259 +/-   0.0533|
| 36 |||   1.5572 +/-   0.0495|
| 37 |||   1.6211 +/-   0.0537|
| 38 |||   1.5785 +/-   0.0477|
| 39 |||   1.5796 +/-   0.0508|
| 40 |||   1.5575 +/-   0.0469|
| 41 |||   1.5647 +/-   0.0507|
| 42 |||   1.5727 +/-   0.0525|
| 43 |||   1.5733 +/-   0.0502|
| 44 |||   1.5449 +/-   0.0500|
| 45 |||   1.5351 +/-   0.0500|
| 46 |||   1.6021 +/-   0.0542|
| 47 |||   1.5817 +/-   0.0549|
| 48 |||   1.5283 +/-   0.0546|
| 49 |||   1.5052 +/-   0.0488|
| 50 |||   1.5470 +/-   0.0502|
| 51 |||   1.5155 +/-   0.0541|
| 52 |||   1.4063 +/-   0.0503|
| 53 |||   1.3161 +/-   0.0530|
| 54 |||   1.2130 +/-   0.0566|
| 55 |||   1.0453 +/-   0.0505|
| 56 |||   0.8588 +/-   0.0386|

## Magnitude of components

Perturbation more generally is `dX = X * ((rand(0,1)-0.5)*delta)`.

If a tensor `X` has perturbation `dX`,
the loss in X (`MSELoss(X,(X+dX))`) is proportional to the MS value of X, `MSELoss(X,0)`

`Loss ~= delta^2 . MS(X) / 12` 

#### Table 2

|layer|MS(img)|MS(txt)|MS(x)|
|-|-|-|-|
|0|0.2379185267857143|0.86640625||
|1|3.9419642857142856|16.07857142857143||
|2|159.14285714285714|59.425||
|3|432.34285714285716|77.43571428571428||
|4|468.6857142857143|89.67857142857143||
|5|471.2857142857143|98.46428571428571||
|6|464.51428571428573|107.60714285714286||
|7|457.8857142857143|118.36428571428571||
|8|447.8857142857143|129.54285714285714||
|9|444.51428571428573|143.3||
|10|444.45714285714286|152.67142857142858||
|11|459.54285714285714|317.6||
|12|472.62857142857143|341.54285714285714||
|13|485.37142857142857|669.3142857142857||
|14|494.85714285714283|786.8571428571429||
|15|537.7714285714286|1230.9714285714285||
|16|517.4285714285714|1324.3428571428572||
|17|551.4285714285714|1544.8||
|18|578.9714285714285|1907.4285714285713||
|19|||21665.82857142857|
|20|||21818.057142857142|
|21|||22009.6|
|22|||22292.571428571428|
|23|||22591.542857142857|
|24|||22879.542857142857|
|25|||22991.085714285713|
|26|||23223.314285714285|
|27|||23763.2|
|28|||24159.085714285713|
|29|||24648.22857142857|
|30|||25391.542857142857|
|31|||26333.257142857143|
|32|||27038.17142857143|
|33|||27914.97142857143|
|34|||28138.057142857142|
|35|||28611.657142857144|
|36|||28104.22857142857|
|37|||28943.542857142857|
|38|||30182.4|
|39|||30598.4|
|40|||31172.571428571428|
|41|||31445.942857142858|
|42|||32617.14285714286|
|43|||33869.71428571428|
|44|||34943.08571428571|
|45|||37085.25714285715|
|46|||39703.77142857143|
|47|||42219.885714285716|
|48|||43724.8|
|49|||45107.2|
|50|||46101.94285714286|
|51|||46447.54285714286|
|52|||46581.02857142857|
|53|||45438.171428571426|
|54|||44768.91428571429|
|55|||44756.114285714284|
|56|||42934.857142857145|

So, if a mean square loss `L` is introduced by an approximation, it is equivalent to a delta
of `delta = sqrt(12*L/R)`, where `R` is the RMS value of layer into which the 
loss was introduced (Table 2).

The impact of delta on the final hidden state is `IMPACT = (100*delta)S`, 
where `S` is the sensitivity of the final hidden state to the one perturbed (Table 1).

So `IMPACT ~ S.sqrt(L/R)`

We can thus create a table of relative importance, `S=1`, `I = 100*sqrt(12)*sqrt(L/R)`

For the impact of an error on the final layer

## Relative Importance

Impact on the final result of a mean square loss of L is `sqrt(L).Table3`

```python
from modules.sensitivity import Sensitivity
impact = Sensitivity.impact_of_mseloss(mse_loss=loss(x,y), before_layer=n, element=Sensitivity.[IMG|TXT|X])
```

#### Table 3

|layer|Q4_1|torch.float8_e4m3fn|Q5_1|Q8_0|
|-|-|-|-|-|
|layer00.img|0.463829066281221|0.28058940247629627|0.27421876104168735|0.13835983568969407|
|layer00.txt|0.41413021095031916|0.14428271194373815|0.22338351393692904|0.062262979043561754|
|layer01.img|0.28405442146008963|0.19578006175180376|0.16780649935302885|0.0832148731739269|
|layer01.txt|0.18723139458070134|0.17911877077913854|0.1206075549880283|0.11116163988957045|
|layer02.img|0.24407406542187499|0.156061894107591|0.13322683710188785|0.07564634184257647|
|layer02.txt|0.16897619915815343|0.24404543881125834|0.14023481329647794|0.1222047830759784|
|layer03.img|0.09239018456457239|0.05861783742224046|0.06351745943345069|0.029804280292965526|
|layer03.txt|0.11580990329135106|0.16453458958135853|0.07220668904800488|0.04389477419769075|
|layer04.img|0.11329493178408309|0.05478842689285124|0.06591266310998531|0.026916081309717545|
|layer04.txt|0.10707748760476256|0.14510619638051203|0.06458000708585138|0.03537574071917392|
|layer05.img|0.07917001103225625|0.040497453845769055|0.04526253523468495|0.01635423086224902|
|layer05.txt|0.08524061639292688|0.1084694956127442|0.052070092324693056|0.02713622488320681|
|layer06.img|0.08910083100215671|0.041674532648867224|0.05056622776174764|0.017941569176604142|
|layer06.txt|0.10062537327529006|0.10569617066872952|0.06054726939671091|0.027351543936847293|
|layer07.img|0.10758104150450966|0.044612520158371374|0.0567273790840741|0.019476344209856746|
|layer07.txt|0.11713082970505799|0.11379574657511353|0.06980951382364749|0.03150324094138766|
|layer08.img|0.10152867607099154|0.04116987335377849|0.05281413886149973|0.01760143241726935|
|layer08.txt|0.1290153821321085|0.10455238634040923|0.07387063551222194|0.031983382287635406|
|layer09.img|0.0973747662633661|0.03999385830533838|0.051013527710090247|0.017680144874050844|
|layer09.txt|0.14319446776447783|0.10536630004500255|0.08265300243944952|0.03379626626396719|
|layer10.img|0.08733621096866714|0.04111128329951996|0.04721830672545835|0.017677870030997505|
|layer10.txt|0.11404341915584226|0.082999452443382|0.06759373190048285|0.034894236253169654|
|layer11.img|0.08989554016836666|0.03506354267605468|0.04652360191278217|0.015683628278907177|
|layer11.txt|0.12070889473539805|0.07402803242948904|0.06909565599558297|0.028556692460337155|
|layer12.img|0.08970840885674193|0.03603522899202655|0.047746224125011|0.01714203999978807|
|layer12.txt|0.11279246887207381|0.06428934335529848|0.06342519133251659|0.03190777496257627|
|layer13.img|0.08990725072042496|0.03272595920949212|0.044673634989314606|0.01585148486115083|
|layer13.txt|0.06267949155692279|0.05951597760555829|0.04218649305171264|0.024279884126307785|
|layer14.img|0.08064891245192612|0.04502811653979269|0.04415433457855433|0.019647483763751743|
|layer14.txt|0.04900556644485384|0.04756604032887899|0.03175650496597352|0.019666578730141868|
|layer15.img|0.08761993228435962|0.03415920638547439|0.03988975534087229|0.013748909796032731|
|layer15.txt|0.068274639631849|0.04173456197048837|0.039539609187197906|0.017937343080989487|
|layer16.img|0.07959848052888037|0.028858419795013582|0.039408994644270445|0.01616499188928569|
|layer16.txt|0.06582334651021912|0.039596373692872576|0.0385445955291342|0.018325570880858982|
|layer17.img|0.07929369881213767|0.022838779184688976|0.034630319438513885|0.012275184437366667|
|layer17.txt|0.09786228116272917|0.046249558996489866|0.05120731716534892|0.020626109306847933|
|layer18.img|0.05826942559120341|inf|0.041675650518199624||
|layer18.txt|0.09196401107843119|inf|0.13628296836026862|inf|
|layer19.x|0.02066333636521075|0.008463588846601337|0.011700573908106776|0.0032580240977909394|
|layer20.x|0.017584393619459987|0.007017964297281785|0.00922363863270032|0.0031308223222000675|
|layer21.x|0.01425488487833232|0.0064604369681355855|0.007971741394927167|0.002688479685899713|
|layer22.x|0.011279795757884391|0.004582766672433847|0.006092049274277014|0.0020586890407461693|
|layer23.x|0.00901117249152316|0.0038160171448475776|0.005486824145017049|0.0016455183913374775|
|layer24.x|0.007199265260846383|0.003100267206747289|0.003852765959329593|0.0012299533886014607|
|layer25.x|0.00756627478402118|0.003184842538678469|0.005059148854779196|0.0017856677012140945|
|layer26.x|0.0076580469242825255|0.004446111593639192|0.0045253581322204596|0.0020977267095090455|
|layer27.x|0.008365742621304214|0.0032075846597872035|0.0039305312012181915|0.0013094462397764183|
|layer28.x|0.009463222968870328|0.0034831911487832982|0.004613365598448253|0.001359484809756548|
|layer29.x|0.009139326276581405|0.004390847538811323|0.004772335032700043|0.0017768787405607776|
|layer30.x|0.009360444440610306|0.0036982793166034883|0.005204056666888473|0.0015337181223052106|
|layer31.x|0.009762399003800298|0.0035852998188184567|0.005045133122401815|0.0012645272398807811|
|layer32.x|0.0102189181708152|0.004214441361939724|0.005378115997589464|0.0013724106685460305|
|layer33.x|0.010234534123381904|0.003936813560340181|0.005417117524671436|0.0013989912129400593|
|layer34.x|0.009959586742520002|0.004050607088374018|0.005367205715594599|0.001471691554038492|
|layer35.x|0.010390925653509558|0.0045742536035973495|0.006683388358028605|0.001839101266812717|
|layer36.x|0.01026969139086216|0.004022325292956493|0.006204407618962405|0.0015000940448939473|
|layer37.x|0.009000484915272545|0.003629199139776215|0.005159675304880897|0.001382295511047849|
|layer38.x|0.008657024412926418|0.0035973106621019265|0.004918403522076477|0.0012147367908393624|
|layer39.x|0.009230645590546854|0.0035311166492467375|0.004757686085983698|0.0014294369417547912|
|layer40.x|0.009233185804164733|0.0035101351655220385|0.005023747287825289|0.0013450523508778335|
|layer41.x|0.00983772415489174|0.0038592549645950053|0.005277183609817837|0.0014826302083450586|
|layer42.x|0.01055453951268037|0.004079246450033149|0.005674050396868742|0.0013655396303030838|
|layer43.x|0.010650460355654175|0.004000884071817562|0.005625059865771267|0.0013853215973997034|
|layer44.x|0.012246276922470026|0.004619945427818696|0.006458377533216772|0.001545521031040765|
|layer45.x|0.013016341948314449|0.004855537686921506|0.006607480686231069|0.0017628859464488057|
|layer46.x|0.01386593555455191|0.0050526785737517385|0.0071174756837396255|0.0016672355335880299|
|layer47.x|0.012476674140025958|0.004619758010226915|0.006604021483869176|0.00136787422392556|
|layer48.x|0.012107611119977883|0.004387644693484229|0.006420152117742616|0.0014293724123241904|
|layer49.x|0.01609510745719652|0.005674809626292927|0.00851344455521222|0.0016840355143400553|
|layer50.x|0.017497403399694803|0.006069706918136041|0.009141215755071565|0.0018651297382322415|
|layer51.x|0.02074296455252106|0.007636357171623467|0.010975066905373908|0.002228897202123878|
|layer52.x|0.020759061869580316|0.007231124986252041|0.010533345735140403|0.002209487276057571|
|layer53.x|0.024701996494539413|0.00852339256654703|0.01215868117084502|0.0026405692813381435|
|layer54.x|0.023529962096889075|0.008300570271153641|0.011623891653033508|0.0023918554210854|
|layer55.x|0.007736308190457637|0.0037672193735187472|0.004119786899144756|0.0012968820236632934|
|layer56.x|0.0037164122890847398|0.0035033042747124954|0.0023442434618423324|0.001784599109630832|
||